# Prompt Ops Mini-Dashboard (Next.js)

A lightweight **Prompt Operations dashboard** built with **Next.js App Router**, demonstrating how teams can **migrate prompts between models** and **evaluate prompt quality across multiple LLMs** using a clean, extensible workflow.

This project focuses on **system design, async workflows, and UX correctness**, rather than raw LLM performance.

---

## ‚ú® Features

### Prompt Migration

* Create prompt migration jobs between source and target models
* Async job execution with lifecycle states:

  * `DRAFT ‚Üí RUNNING ‚Üí COMPLETED`
* Row-level loading indicators
* Detail view showing source vs migrated prompts
* Copy-to-clipboard for migrated prompts

### Prompt Evaluation

* Create evaluations across multiple models
* Configurable **relative scoring weights** (clarity, specificity, safety)
* Async evaluation runs:

  * `QUEUED ‚Üí RUNNING ‚Üí DONE`
* Rubric-based scoring (0‚Äì100)
* Best-model highlighting
* Export results as JSON (bonus)

---

## üß± Architecture Overview

* **Next.js App Router** (v15+ compatible)
* **Route Handlers** for API endpoints
* **In-memory data store** (mocked persistence)
* **Client components** for interactivity
* **Reusable UI components**:

  * `<DataTable />` (shared list layout)
  * `<TableSkeleton />` (loading states)
  * `<StatusBadge />`, `<Spinner />`
* **tweakcn / shadcn-style theming** with semantic tokens

---

## üìÅ Project Structure (Simplified)

```
src/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ prompt-migration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ new/page.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [id]/page.tsx
‚îÇ   ‚îú‚îÄ‚îÄ prompt-evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ new/page.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [id]/page.tsx
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ migrations/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ route.ts
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [id]/
|       |        ‚îú‚îÄ‚îÄ route.ts 
|       |        ‚îî‚îÄ‚îÄ start/route.ts
|       |            
‚îÇ       ‚îî‚îÄ‚îÄ evaluations/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ route.ts
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [id]/
|       |        ‚îú‚îÄ‚îÄ route.ts 
|       |        ‚îî‚îÄ‚îÄ run/route.ts
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ DataTable.tsx
‚îÇ   ‚îú‚îÄ‚îÄ TableSkeleton.tsx
‚îÇ   ‚îú‚îÄ‚îÄ StatusBadge.tsx
|   ‚îú‚îÄ‚îÄ Pagination.tsx 
‚îÇ   ‚îî‚îÄ‚îÄ Spinner.tsx
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ models.ts
|   ‚îú‚îÄ‚îÄ query.ts
‚îÇ   ‚îú‚îÄ‚îÄ scoring.ts
|   ‚îú‚îÄ‚îÄ scoring.test.ts
|   ‚îú‚îÄ‚îÄ store.ts
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts
```

---

## üîå API Endpoints

### Prompt Migration

* `GET /api/migrations` ‚Äî list migrations
* `POST /api/migrations` ‚Äî create migration
* `GET /api/migrations/:id` ‚Äî migration detail
* `POST /api/migrations/:id/start` ‚Äî start migration

### Prompt Evaluation

* `GET /api/evaluations` ‚Äî list evaluations
* `POST /api/evaluations` ‚Äî create evaluation
* `GET /api/evaluations/:id` ‚Äî evaluation detail
* `POST /api/evaluations/:id/run` ‚Äî run evaluation

All async behavior is simulated to demonstrate workflow handling.

---

## ‚öñÔ∏è Scoring Logic (Prompt Evaluation)

* Each criterion (clarity, specificity, safety) is scored in the range **60‚Äì100**
* User inputs **relative importance weights**
* Weights are **normalized internally**
* Overall score is a weighted average in the range **0‚Äì100**

This ensures:

* Mathematical correctness
* Intuitive UX
* Reviewer-friendly explainability

---

## üß™ Testing

* Lightweight **Jest + ts-jest** setup
* Focused unit tests for:

  * Scoring normalization logic
  * Query parameter utilities
* Manual testing for all critical UI flows

Example test coverage:

* Overall score always within `0‚Äì100`
* Query params update correctly

This balances confidence without over-engineering.

---

## ‚ôø Accessibility

* Semantic labels for all inputs
* Keyboard-friendly forms
* Accessible sliders for scoring weights
* Clear focus states and readable empty/loading states

---

## üöÄ Deployment

The application is deployed on **Vercel**.

> **Note:**
> This project uses **in-memory storage** for migrations and evaluations.
> Data resets on redeploy or cold starts.
> This is intentional for the scope of the assignment.

In a production system, this layer would be replaced with persistent storage (e.g. PostgreSQL, Redis, or a job queue).

---

## ‚ñ∂Ô∏è Demo Video (Optional)

A short (1‚Äì2 minute) screencast demonstrates:

1. Creating a prompt migration
2. Running the migration and viewing results
3. Creating a prompt evaluation
4. Running evaluation and comparing model scores

*(Link to video can be added here.)*

---

## üß† Design Decisions & Trade-offs

* **In-memory store** instead of a database for simplicity
* **Mocked async jobs** to focus on workflow and UX
* **Selective abstraction** (DataTable, Skeletons) to avoid premature complexity
* **Client-side polling** instead of WebSockets for clarity

These choices keep the project focused, readable, and easy to extend.

---

## üèÅ Conclusion

This mini-dashboard demonstrates:

* Async job lifecycle handling
* Clean Next.js App Router usage
* Thoughtful UX and accessibility
* Practical abstraction and testing discipline

It is designed to be **easy to reason about**, **easy to review**, and **easy to extend**.